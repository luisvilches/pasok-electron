"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.computeBlockMap = exports.createPackageFileInfo = exports.createDifferentialPackage = undefined;

var _bluebirdLst;

function _load_bluebirdLst() {
    return _bluebirdLst = require("bluebird-lst");
}

var _bluebirdLst2;

function _load_bluebirdLst2() {
    return _bluebirdLst2 = _interopRequireDefault(require("bluebird-lst"));
}

/*
Approach like AppX block map, but with one difference - block not compressed individually, instead, the whole file is compressed using LZMA compression.
See (Package File in the developer readme) about compression. So, delta will be not ideal (because compressed data can change not only actually changed block in the file, but others,
and we don't set even dict size and default 64M is used), but full package size will be still relative small and will save initial download time/costs.
 */
// reduce dict size to avoid large block invalidation on change
let createDifferentialPackage = exports.createDifferentialPackage = (() => {
    var _ref = (0, (_bluebirdLst || _load_bluebirdLst()).coroutine)(function* (archiveFile) {
        // compute block map using compressed file data
        const sevenZFile = new (_SevenZFile || _load_SevenZFile()).SevenZFile(archiveFile);
        try {
            const archive = yield sevenZFile.read();
            const blockMap = yield computeBlockMap(sevenZFile);
            sevenZFile.close();
            const blockMapDataString = (0, (_jsYaml || _load_jsYaml()).safeDump)(blockMap);
            if (process.env.DEBUG_BLOCKMAP) {
                yield (0, (_fsExtraP || _load_fsExtraP()).writeFile)(archiveFile + ".blockMap.yml", blockMapDataString);
            }
            const blockMapFileData = yield deflateRaw(blockMapDataString, { level: 9 });
            yield (0, (_fsExtraP || _load_fsExtraP()).appendFile)(archiveFile, blockMapFileData);
            const packageFileInfo = yield createPackageFileInfo(archiveFile);
            packageFileInfo.headerSize = archive.headerSize;
            packageFileInfo.blockMapSize = blockMapFileData.length;
            packageFileInfo.blockMapData = blockMapDataString;
            return packageFileInfo;
        } catch (e) {
            sevenZFile.close();
            throw e;
        }
    });

    return function createDifferentialPackage(_x) {
        return _ref.apply(this, arguments);
    };
})();

let createPackageFileInfo = exports.createPackageFileInfo = (() => {
    var _ref2 = (0, (_bluebirdLst || _load_bluebirdLst()).coroutine)(function* (file) {
        return {
            file,
            size: (yield (0, (_fsExtraP || _load_fsExtraP()).stat)(file)).size,
            sha512: yield (0, (_builderUtil || _load_builderUtil()).hashFile)(file)
        };
    });

    return function createPackageFileInfo(_x2) {
        return _ref2.apply(this, arguments);
    };
})();

let computeBlockMap = exports.computeBlockMap = (() => {
    var _ref3 = (0, (_bluebirdLst || _load_bluebirdLst()).coroutine)(function* (sevenZFile) {
        const archive = sevenZFile.archive;
        const builder = new BlockMapBuilder(archive);
        const files = [];
        for (const file of archive.files) {
            if (!file.isDirectory) {
                builder.buildFile(file);
                // do not add empty files
                if (file.dataStart !== file.dataEnd) {
                    files.push(file);
                }
            }
        }
        // just to be sure that file data really doesn't have gap and grouped one by one
        for (let i = 0; i < files.length - 1; i++) {
            if (files[i].dataEnd !== files[i + 1].dataStart) {
                throw new Error("Must be no gap");
            }
        }
        const stats = [];
        const blocks = yield (_bluebirdLst2 || _load_bluebirdLst2()).default.map(files, (() => {
            var _ref4 = (0, (_bluebirdLst || _load_bluebirdLst()).coroutine)(function* (entry) {
                const chunker = new (_ContentDefinedChunker || _load_ContentDefinedChunker()).ContentDefinedChunker();
                const blocks = yield chunker.computeChunks(sevenZFile.fd, entry.dataStart, entry.dataEnd, entry.name);
                if (process.env.DEBUG_BLOCKMAP) {
                    stats.push(getStat(blocks.sizes, entry.name));
                }
                return Object.assign({ name: entry.name.replace(/\\/g, "/"), offset: entry.dataStart, size: entry.dataEnd - entry.dataStart }, blocks);
            });

            return function (_x4) {
                return _ref4.apply(this, arguments);
            };
        })(), { concurrency: 2 });
        if (process.env.DEBUG_BLOCKMAP) {
            let duplicate = 0;
            let savedSize = 0;
            // noinspection JSMismatchedCollectionQueryUpdate
            const checksums = [];
            // noinspection JSMismatchedCollectionQueryUpdate
            const sizes = [];
            const index = new Map();
            for (const file of blocks) {
                for (let i = 0; i < file.checksums.length; i++) {
                    const checksum = file.checksums[i];
                    const size = file.sizes[i];
                    if (index.has(checksum)) {
                        duplicate++;
                        savedSize += size;
                    } else {
                        index.set(checksum, checksums.length);
                        checksums.push(checksum);
                        sizes.push(size);
                    }
                }
            }
            console.log(stats.join("\n"));
            console.log(`duplicates: ${duplicate}, saved: ${savedSize}`);
        }
        return {
            version: "2",
            files: blocks
        };
    });

    return function computeBlockMap(_x3) {
        return _ref3.apply(this, arguments);
    };
})();

var _builderUtil;

function _load_builderUtil() {
    return _builderUtil = require("builder-util");
}

var _blockMapApi;

function _load_blockMapApi() {
    return _blockMapApi = require("builder-util-runtime/out/blockMapApi");
}

var _fsExtraP;

function _load_fsExtraP() {
    return _fsExtraP = require("fs-extra-p");
}

var _jsYaml;

function _load_jsYaml() {
    return _jsYaml = require("js-yaml");
}

var _SevenZFile;

function _load_SevenZFile() {
    return _SevenZFile = require("./SevenZFile");
}

var _ContentDefinedChunker;

function _load_ContentDefinedChunker() {
    return _ContentDefinedChunker = require("./ContentDefinedChunker");
}

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const deflateRaw = (_bluebirdLst2 || _load_bluebirdLst2()).default.promisify(require("zlib").deflateRaw);
class BlockMapBuilder {
    constructor(archive) {
        this.archive = archive;
        this.currentFolderIndex = -1;
    }
    // noinspection BadExpressionStatementJS
    buildFile(file) {
        const archive = this.archive;
        const folderIndex = file.blockIndex;
        if (folderIndex < 0) {
            // empty file
            file.dataStart = 0;
            file.dataEnd = 0;
            return;
        }
        if (folderIndex === this.currentFolderIndex) {
            throw new Error("Solid not supported");
        }
        this.currentFolderIndex = folderIndex;
        const folder = archive.folders[folderIndex];
        const firstPackStreamIndex = folder.firstPackedStreamIndex;
        const folderOffset = (_blockMapApi || _load_blockMapApi()).SIGNATURE_HEADER_SIZE + archive.packPosition + archive.streamMap.packStreamOffsets[firstPackStreamIndex];
        let size = 0;
        for (let i = 0; i < folder.packedStreams.length; i++) {
            size += archive.packedSizes[firstPackStreamIndex + i];
        }
        file.dataStart = folderOffset;
        file.dataEnd = folderOffset + size;
        // console.log(`${file.name} ${size}, ${folder.totalInputStreams}`)
    }
}

function getStat(sizes, name) {
    const sortedSizes = sizes.slice().sort((a, b) => a - b);
    const middle = Math.floor(sortedSizes.length / 2);
    const isEven = sortedSizes.length % 2 === 0;
    const median = isEven ? (sortedSizes[middle] + sortedSizes[middle - 1]) / 2 : sortedSizes[middle];
    return `${sizes.length} chunks generated for ${name} (min: ${sortedSizes[0]}, max: ${sortedSizes[sortedSizes.length - 1]}, median: ${median})`;
}
//# sourceMappingURL=blockMap.js.map